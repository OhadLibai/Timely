# docker-compose.yml

services:
  postgres:
    image: postgres:15-alpine
    container_name: timely-postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-timely_db}
      POSTGRES_USER: ${POSTGRES_USER:-timely_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-timely_password}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-timely_user} -d ${POSTGRES_DB:-timely_db}"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: timely-redis
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: timely-backend
    env_file:
      - ./backend/.env
    environment:
      NODE_ENV: ${NODE_ENV:-development} # Default to development
      PORT: ${PORT:-5000}
    ports:
      - "${BACKEND_PORT:-5000}:5000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./backend/uploads:/app/uploads
      - ./backend:/app # Mount local backend code for development
      - /app/node_modules # Prevent local node_modules from overwriting container's
    command: npm start # Use 'npm start' for production builds

  ml-service:
    build:
      context: ./ml-service
      dockerfile: Dockerfile
    container_name: timely-ml-service
    env_file:
      - ./ml-service/.env
    environment:
      PROCESSED_DATA_PATH: /app/data/processed # For runtime access by API
      RAW_DATA_PATH: /app/data # For runtime access to raw data if needed by API
      MODEL_PATH: /app/models
      PYTHONUNBUFFERED: 1
    ports:
      - "${ML_SERVICE_PORT:-8000}:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      train-model: # Wait for initial model training if this service relies on a model existing at startup
        condition: service_completed_successfully
    volumes:
      - ./ml-service/models:/app/models # Trained models
      - ./ml-service/data:/app/data   # Raw and processed data
      - ./ml-service/src:/app/src     # Mount local ML code for development
    command: uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --reload

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args: # Build-time args for Vite
        VITE_API_URL: ${VITE_API_URL:-http://localhost:5000/api}
        VITE_ML_API_URL: ${VITE_ML_API_URL:-http://localhost:8000/api} # If frontend calls ML service directly
    container_name: timely-frontend
    ports:
      - "${FRONTEND_PORT:-3000}:80" # Nginx serves on port 80 in container
    depends_on:
      - backend
      # - ml-service # Only if frontend directly calls ML service
    volumes:
      - ./frontend/nginx.conf:/etc/nginx/conf.d/default.conf
      # For Vite dev server instead of Nginx build:
      # - ./frontend:/app
      # - /app/node_modules
    # command: npm run dev # If not using Nginx

  migrate:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: timely-migrate
    env_file:
      - ./backend/.env
    depends_on:
      postgres:
        condition: service_healthy
    command: npm run migrate # Assumes migrate script in backend/package.json
    restart: "no"

  seed:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: timely-seed
    env_file:
      - ./backend/.env
    depends_on:
      migrate:
        condition: service_completed_successfully
    command: npm run seed # Assumes seed script in backend/package.json
    restart: "no"

  train-model: # Service to preprocess, train model, and populate staging DB
    build:
      context: ./ml-service
      dockerfile: Dockerfile
    container_name: timely-train-model
    env_file:
      - ./ml-service/.env
    environment:
      PROCESSED_DATA_PATH: /app/data/processed # Output/Input for scripts
      RAW_DATA_PATH: /app/data # Input for preprocessing & DB population
      MODEL_PATH: /app/models # Output for trained model
      PYTHONUNBUFFERED: 1
    depends_on:
      seed: # Ensure backend seeding (like categories by seed.ts, or just DB ready)
        condition: service_completed_successfully
      # Or just postgres: condition: service_healthy, if category seeding is handled by training-script
    volumes:
      - ./ml-service/models:/app/models
      - ./ml-service/data:/app/data # Mount the entire data directory
      - ./ml-service/src:/app/src   # Mount source code
    command: >
      sh -c "mkdir -p /app/data/processed && # Ensure processed dir exists
             echo '--- Starting Data Preprocessing ---' &&
             python -m src.preprocessing.data_preprocessing &&
             echo '--- Data Preprocessing Complete ---' &&
             echo '--- Starting Model Training & Evaluation (includes DB staging population) ---' &&
             python -m src.training.train_model &&
             echo '--- Model Training & Evaluation Complete ---'"
    restart: "no"

  sync-products: # Service to sync products from staging to main table
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: timely-sync-products
    env_file:
      - ./backend/.env
    environment:
      NODE_ENV: development # Or specific environment for the script
    depends_on:
      train-model: # Runs after train-model (which includes populating products_staging)
        condition: service_completed_successfully
    command: npm run db:sync-products # Script in backend/package.json
    restart: "no"

volumes:
  postgres_data:
  redis_data:

networks:
  default:
    name: timely-network