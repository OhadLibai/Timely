# ml-service/src/services/feature_engineering.py
import pandas as pd
import numpy as np
import os
from typing import List, Dict

class FeatureEngineer:
    def __init__(self, processed_data_path: str):
        """
        Loads pre-computed, GLOBAL dataframes. 
        For live prediction, we avoid re-calculating global stats for all products.
        Instead, we pre-compute them and load them here. The dynamic, user-specific
        features will be calculated on the fly.
        """
        self.path = processed_data_path
        self.products_info_df = None
        self.prod_global_features_df = None
        self._load_precomputed_data()

    def _load_precomputed_data(self):
        """
        Loads the necessary pre-computed CSVs.
        These files should be generated by a script that processes the full dataset,
        creating global aggregates that we can use for real-time predictions.
        """
        try:
            # Load basic product info (aisle, department)
            # This corresponds to the merge logic in `_add_product_features` in the training script.
            products_df = pd.read_csv(os.path.join(self.path, "products.csv"))
            aisles_df = pd.read_csv(os.path.join(self.path, "aisles.csv"))
            departments_df = pd.read_csv(os.path.join(self.path, "departments.csv"))
            self.products_info_df = products_df.merge(aisles_df, on='aisle_id').merge(departments_df, on='department_id')

            # Load GLOBAL product features (popularity, reorder rate)
            # This pre-calculates the work done in `_add_product_features`
            self.prod_global_features_df = pd.read_csv(os.path.join(self.path, "prod_features.csv")).set_index('product_id')

            print("FeatureEngineer: Pre-computed data loaded successfully.")
        except FileNotFoundError as e:
            print(f"ERROR in FeatureEngineer: Could not load pre-computed data from {self.path}. Details: {e}")
            raise e

    def generate_features_for_user(self, user_id: str, order_history: List[Dict]) -> pd.DataFrame:
        """
        Generates a feature DataFrame for a single user for real-time prediction.
        This logic now exactly mirrors the logic in `data_preprocessing.py`.

        Args:
            user_id: The ID of the user.
            order_history: The user's past orders from the database.

        Returns:
            A pandas DataFrame with features for the model.
        """
        if not order_history:
            return pd.DataFrame()

        # Create a DataFrame from the user's personal order history
        # This mirrors the structure needed for the training script's calculations.
        history_df = pd.DataFrame(order_history)
        user_product_history = history_df.explode('products').rename(columns={'products': 'product_id'})

        if user_product_history.empty:
            return pd.DataFrame()
            
        # --- 1. Calculate DYNAMIC User-level Features ---
        # This section now mirrors the 'User-level Features' aggregation in `extract_features`.
        user_total_orders = history_df['order_id'].nunique()
        user_avg_days_between_orders = history_df['days_since_prior_order'].mean()
        user_std_days_between_orders = history_df['days_since_prior_order'].std()
        user_favorite_dow = history_df['order_dow'].mode()[0] if not history_df['order_dow'].empty else 0
        user_favorite_hour = history_df['order_hour_of_day'].mode()[0] if not history_df['order_hour_of_day'].empty else 12


        # --- 2. Calculate DYNAMIC User-Product Features ---
        # This section now mirrors the 'User-Product Features' aggregation in `extract_features`.
        up_features = user_product_history.groupby('product_id').agg(
            user_product_orders=('order_id', 'nunique'),
            user_product_first_order=('order_number', 'min'),
            user_product_last_order=('order_number', 'max')
        ).reset_index()

        # Create the base DataFrame with all products the user has ever ordered.
        features_df = pd.DataFrame({'product_id': up_features['product_id']})
        features_df = features_df.merge(up_features, on='product_id', how='left')


        # --- 3. Add all features to the DataFrame ---
        
        # Add dynamic user features
        features_df['user_total_orders'] = user_total_orders
        features_df['user_avg_days_between_orders'] = user_avg_days_between_orders
        features_df['user_std_days_between_orders'] = user_std_days_between_orders
        features_df['user_favorite_dow'] = user_favorite_dow
        features_df['user_favorite_hour'] = user_favorite_hour

        # Calculate derived User-Product features, mirroring `extract_features`
        features_df['user_product_order_rate'] = features_df['user_product_orders'] / features_df['user_total_orders']
        features_df['user_product_orders_since_last'] = features_df['user_total_orders'] - features_df['user_product_last_order']

        # Merge pre-computed GLOBAL product features, mirroring `_add_product_features`
        features_df = features_df.merge(self.products_info_df[['product_id', 'aisle_id', 'department_id']], on='product_id', how='left')
        
        # Merge global product stats from the pre-computed file
        # We use .get() for safe merging from the indexed dataframe.
        features_df['product_total_orders'] = features_df['product_id'].apply(lambda x: self.prod_global_features_df.get('product_total_orders', {}).get(x, 0))
        features_df['product_reorder_rate'] = features_df['product_id'].apply(lambda x: self.prod_global_features_df.get('product_reorder_rate', {}).get(x, 0))


        # --- 4. Final Cleanup and Column Selection ---
        # This list of columns now EXACTLY matches the feature set from the training script.
        final_feature_columns = [
            'user_total_orders', 'user_avg_days_between_orders', 'user_std_days_between_orders',
            'user_favorite_dow', 'user_favorite_hour', 'user_product_orders', 
            'user_product_first_order', 'user_product_last_order', 'user_product_order_rate',
            'user_product_orders_since_last', 'aisle_id', 'department_id',
            'product_total_orders', 'product_reorder_rate'
        ]
        
        # Ensure all required columns exist, reorder, and fill NaNs
        final_df = features_df.reindex(columns=final_feature_columns).fillna(0)

        print(f"Successfully generated a feature matrix of shape {final_df.shape} for user {user_id}")
        return final_df